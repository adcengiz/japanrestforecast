{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import CategoricalEncoder\n",
    "import category_encoders as ce\n",
    "import collections as col\n",
    "from cvxpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_store = pd.read_csv('data/air_store_info.csv')\n",
    "\n",
    "date_info = pd.read_csv('data/date_info.csv')\n",
    "date_info_drop = date_info.drop('day_of_week', axis=1)\n",
    "date_info_drop.columns.values[0]='visit_date'\n",
    "\n",
    "store_id = pd.read_csv('data/store_id_relation.csv', index_col='air_store_id')\n",
    "air_visit1 = pd.read_csv('data/air_visit_data.csv')\n",
    "air_reserve1 = pd.read_csv('data/air_reserve.csv')\n",
    "\n",
    "weather_data1 = pd.read_csv('data/merged_rest_data_weather_measurements.csv')\n",
    "weather_data = weather_data1[['air_store_id', \n",
    "                              'visit_date', \n",
    "                              'avg_temperature1', \n",
    "                              'high_temperature1', \n",
    "                              'low_temperature1',\n",
    "                              'hours_sunlight1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop duplicates in air_reserve data, and sum according to dates\n",
    "air_reserve = air_reserve1[air_reserve1.duplicated()==False]\n",
    "#air_reserve.duplicated().sum()\n",
    "air_reserve['visit_datetime'] = air_reserve['visit_datetime'].apply(lambda _: _[:10])\n",
    "air_reserve = air_reserve.drop(['reserve_datetime'], axis=1)\\\n",
    "              .groupby(['air_store_id', 'visit_datetime'])['reserve_visitors']\\\n",
    "              .sum().reset_index().rename(columns = {'visit_datetime':'visit_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id_pool = list(set(air_visit1['air_store_id']))\n",
    "dictionary = {}\n",
    "for storeid in id_pool:\n",
    "    dictionary[storeid] = air_visit1.loc[air_visit1['air_store_id'] == storeid]\n",
    "    dictionary[storeid]['minus7days'] = dictionary[storeid]['visitors'].shift(7)\n",
    "    dictionary[storeid]['minus1days'] = dictionary[storeid]['visitors'].shift(1)\n",
    "    dictionary[storeid]['MA'] = dictionary[storeid].rolling(window=7)['minus1days'].mean()\n",
    "frames = []\n",
    "for storeid in id_pool:\n",
    "    frames.append(dictionary[storeid])\n",
    "df = pd.concat(frames).dropna(axis=0, how='any')\n",
    "\n",
    "tmp0 = pd.merge(df,\n",
    "                date_info_drop,\n",
    "                on='visit_date',\n",
    "                how = 'left')\n",
    "tmp0['holiday_flg'] = tmp0['holiday_flg'].astype('category')\n",
    "tmp1 = pd.merge(tmp0,\n",
    "                air_reserve,\n",
    "                on=['air_store_id', 'visit_date'],\n",
    "                how = 'left')\n",
    "tmp2 = pd.merge(tmp1,\n",
    "                air_store,\n",
    "                on='air_store_id',\n",
    "                how = 'left')\n",
    "tmp3 = pd.merge(tmp2,\n",
    "               weather_data,\n",
    "               on=['air_store_id', 'visit_date'],\n",
    "               how = 'left')\n",
    "air_visit_reserve_merge = tmp3.dropna(axis=0, how='any').drop_duplicates()\n",
    "\n",
    "air_visit_reserve_merge['visit_date'] = pd.to_datetime(air_visit_reserve_merge['visit_date'])\n",
    "air_visit_reserve_merge['day'] = air_visit_reserve_merge['visit_date'].dt.day\n",
    "air_visit_reserve_merge['weekday'] = air_visit_reserve_merge['visit_date'].dt.weekday\n",
    "\n",
    "air_visit_reserve_merge['day'] = air_visit_reserve_merge['day'].astype('category')\n",
    "air_visit_reserve_merge['weekday'] = air_visit_reserve_merge['weekday'].astype('category')\n",
    "\n",
    "onehot_day_weekday = pd.get_dummies(air_visit_reserve_merge[['day', 'weekday']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geoweekday = pd.pivot_table(air_visit_reserve_merge[['weekday', 'visitors', 'air_area_name']], \n",
    "               index='weekday', \n",
    "               columns=['air_area_name'], \n",
    "               aggfunc=np.sum).fillna(0)\n",
    "\n",
    "area_list=[]\n",
    "for i in [0,6,9,12,20,37]:\n",
    "    area_list.append(geoweekday.columns.tolist()[i][1])\n",
    "\n",
    "l1 = air_visit_reserve_merge['air_area_name'].tolist()\n",
    "l2 = air_visit_reserve_merge['weekday'].tolist()\n",
    "l1bool = [elem in area_list for elem in l1]\n",
    "l2bool = [elem==5 for elem in l2]\n",
    "lbool = [int(l1bool[i]&l2bool[i]) for i in range(len(l1))]\n",
    "air_visit_reserve_merge['geotemp'] = lbool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#holiday_flg, day, weekday, genre_label_encoding, area_label_encoding\n",
    "df_with_label_encoding[['holiday_flg', 'day', 'weekday', 'genre_label_encoding', 'area_label_encoding']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in ['holiday_flg', 'day', 'weekday', 'genre_label_encoding', 'area_label_encoding', 'geotemp']:\n",
    "        print(df_with_label_encoding[name].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "corr_df = air_visit_reserve_merge[['visitors',\n",
    "                                   'minus7days', \n",
    "                                     'minus1days', \n",
    "                                     'MA', \n",
    "                                     'reserve_visitors', \n",
    "                                     'avg_temperature1', \n",
    "                                     'high_temperature1', \n",
    "                                     'low_temperature1', \n",
    "                                     'hours_sunlight1']].corr()\n",
    "\n",
    "sns.heatmap(corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geodate = pd.pivot_table(air_visit_reserve_merge[['visit_date', 'visitors', 'air_area_name']], \n",
    "               index='visit_date', \n",
    "               columns=['air_area_name'], \n",
    "               aggfunc=np.sum).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "plotly.tools.set_credentials_file(username=\"\", api_key=\"\")\n",
    "\n",
    "data = [go.Surface(z=geodate.values.tolist(), colorscale='Viridis')]\n",
    "\n",
    "layout = go.Layout(\n",
    "    width=800,\n",
    "    height=700,\n",
    "    autosize=False,\n",
    "    title='geo_weekday',\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            gridcolor='rgb(255, 255, 255)',\n",
    "            zerolinecolor='rgb(255, 255, 255)',\n",
    "            showbackground=True,\n",
    "            backgroundcolor='rgb(230, 230,230)'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            gridcolor='rgb(255, 255, 255)',\n",
    "            zerolinecolor='rgb(255, 255, 255)',\n",
    "            showbackground=True,\n",
    "            backgroundcolor='rgb(230, 230,230)'\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            gridcolor='rgb(255, 255, 255)',\n",
    "            zerolinecolor='rgb(255, 255, 255)',\n",
    "            showbackground=True,\n",
    "            backgroundcolor='rgb(230, 230,230)'\n",
    "        ),\n",
    "        aspectratio = dict( x=1, y=1, z=0.7 ),\n",
    "        aspectmode = 'manual'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "\n",
    "plotly.plotly.iplot(fig, filename='geodate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "geoday = pd.pivot_table(air_visit_reserve_merge[['day', 'visitors', 'air_area_name']], \n",
    "               index='day', \n",
    "               columns=['air_area_name'], \n",
    "               aggfunc=np.sum).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "air_visit_reserve_merge['air_genre_name'] =\\\n",
    "    air_visit_reserve_merge['air_genre_name'].astype('category')\n",
    "air_visit_reserve_merge['air_area_name'] =\\\n",
    "    air_visit_reserve_merge['air_area_name'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le_genre = LabelEncoder()\n",
    "le_genre.fit(air_visit_reserve_merge['air_genre_name'])\n",
    "df_genre_label_encoding = pd.DataFrame(le_genre.transform(air_visit_reserve_merge['air_genre_name']),\n",
    "                                       columns=['genre_label_encoding'])\n",
    "\n",
    "le_area = LabelEncoder()\n",
    "le_area.fit(air_visit_reserve_merge['air_area_name'])\n",
    "df_area_label_encoding = pd.DataFrame(le_area.transform(air_visit_reserve_merge['air_area_name']),\n",
    "                                       columns=['area_label_encoding'])\n",
    "\n",
    "df_label_encoding = pd.merge(df_genre_label_encoding, df_area_label_encoding, left_index=True, right_index=True)\n",
    "df_label_encoding['genre_label_encoding'] = df_label_encoding['genre_label_encoding'].astype('category')\n",
    "df_label_encoding['area_label_encoding'] = df_label_encoding['area_label_encoding'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_label_encoding.index = air_visit_reserve_merge.index\n",
    "\n",
    "df_with_label_encoding = pd.merge(air_visit_reserve_merge, \n",
    "                                  df_label_encoding, \n",
    "                                  right_index=True, left_index=True)\\\n",
    "                            .dropna(axis=0, how='any')\\\n",
    "                            .drop(['air_genre_name',\n",
    "                                    'air_area_name',\n",
    "                                    'latitude',\n",
    "                                    'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_onehot1 = pd.get_dummies(air_visit_reserve_merge, \n",
    "                               columns=['air_genre_name','air_area_name'])\\\n",
    "                    .dropna(axis=0, how='any')\\\n",
    "                    .drop(['latitude',\n",
    "                            'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_onehot = pd.merge(df_with_onehot1, \n",
    "         onehot_day_weekday, \n",
    "         how='outer', \n",
    "         left_index=True, \n",
    "         right_index=True).drop(['day','weekday'], \n",
    "                                axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_target = ce.TargetEncoder(cols = ['air_genre_name', 'air_area_name'])\n",
    "tmp_encoder_target = encoder_target.fit_transform(air_visit_reserve_merge[['air_genre_name', \n",
    "                                                                           'air_area_name']],\n",
    "                                                  air_visit_reserve_merge['visitors'])\n",
    "tmp_encoder_target = tmp_encoder_target.rename(index=str, \n",
    "                                               columns={'air_genre_name':'air_genre_name_encoding',\n",
    "                                                        'air_area_name':'air_area_name_encoding'})\n",
    "tmp_encoder_target['air_genre_name_encoding'] = tmp_encoder_target['air_genre_name_encoding'].astype('category')\n",
    "tmp_encoder_target['air_area_name_encoding'] = tmp_encoder_target['air_area_name_encoding'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_encoder_target.index = tmp_encoder_target.index.map(int)\n",
    "df_with_target_encoding = pd.concat([air_visit_reserve_merge, tmp_encoder_target], axis=1)\\\n",
    "                            .dropna(axis=0, how='any')\\\n",
    "                            .drop(['air_genre_name',\n",
    "                                    'air_area_name',\n",
    "                                    'latitude',\n",
    "                                    'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_baseline = air_visit_reserve_merge[['air_store_id', 'visit_date', 'visitors', 'minus7days']]\n",
    "df_baseline['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_dates = geodate[206:].index.astype(str).tolist()\n",
    "new_df_list = []\n",
    "name_list = [df_baseline, df_with_onehot, df_with_label_encoding]\n",
    "for name in name_list:\n",
    "    new_df_list.append(name[name['visit_date'].isin(new_dates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def designed_train_test_split(df):\n",
    "    df['visit_date'] = df['visit_date'].astype(str)\n",
    "    test_date_selector = df[\"visit_date\"].str.startswith(\"2017-04\")\n",
    "    val_date_selector = df[\"visit_date\"].str.startswith(\"2017-03\")\n",
    "    df_test = df[test_date_selector].drop(['air_store_id', 'visit_date'], axis=1)\n",
    "    df_val = df[val_date_selector].drop(['air_store_id', 'visit_date'], axis=1)\n",
    "    df_train = df[~(test_date_selector | val_date_selector)].drop(['air_store_id', 'visit_date'], axis=1)\n",
    "    \n",
    "    df_train_y = df_train['visitors']\n",
    "    df_train_X = df_train.drop(['visitors'], axis=1)\n",
    "    df_val_y = df_val['visitors']\n",
    "    df_val_X = df_val.drop(['visitors'], axis=1)\n",
    "    df_test_y = df_test['visitors'] #true y\n",
    "    df_test_X = df_test.drop(['visitors'], axis=1)     \n",
    "\n",
    "    return df_train_X, df_train_y, df_val_X, df_val_y, df_test_X, df_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainValTest_dict = col.OrderedDict([\n",
    "    (\"df_train_X\", []),\n",
    "    (\"df_train_y\", []),\n",
    "    (\"df_val_X\", []),\n",
    "    (\"df_val_y\", []),\n",
    "    (\"df_test_X\", []),\n",
    "    (\"df_test_y\", []),\n",
    "])\n",
    "df_name_list = [df_baseline, df_with_target_encoding, df_with_onehot, df_with_label_encoding]\n",
    "for name in df_name_list:\n",
    "    tmp_train_X, tmp_train_y, tmp_val_X, tmp_val_y, tmp_test_X, tmp_test_y = designed_train_test_split(name)\n",
    "    TrainValTest_dict['df_train_X'].append(tmp_train_X)\n",
    "    TrainValTest_dict['df_train_y'].append(tmp_train_y)\n",
    "    TrainValTest_dict['df_val_X'].append(tmp_val_X)\n",
    "    TrainValTest_dict['df_val_y'].append(tmp_val_y)\n",
    "    TrainValTest_dict['df_test_X'].append(tmp_test_X)\n",
    "    TrainValTest_dict['df_test_y'].append(tmp_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_func(prediction, true):\n",
    "    num_samples = true.shape[0]\n",
    "    evaluation = np.linalg.norm(np.divide(prediction-true, true), ord=1)/num_samples\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_train = lgb.Dataset(TrainValTest_dict['df_train_X'][3], TrainValTest_dict['df_train_y'][3])\n",
    "lgb_eval = lgb.Dataset(TrainValTest_dict['df_val_X'][3], TrainValTest_dict['df_val_y'][3], reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'mape',\n",
    "    'num_leaves': 29,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'min_data_in_leaf': 380,\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, \n",
    "               lgb_train, \n",
    "               num_boost_round=1000, \n",
    "               valid_sets=lgb_eval, \n",
    "               feature_name='auto', \n",
    "               categorical_feature='auto', \n",
    "               early_stopping_rounds=None,\n",
    "               )\n",
    "\n",
    "y_pred = gbm.predict(TrainValTest_dict['df_test_X'][3], num_iteration=gbm.best_iteration)\n",
    "\n",
    "score_func(y_pred, TrainValTest_dict['df_test_y'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    TrainValTest_dict['df_train_X'][i] = np.array(TrainValTest_dict['df_train_X'][i])\n",
    "    TrainValTest_dict['df_val_X'][i] = np.array(TrainValTest_dict['df_val_X'][i])\n",
    "    TrainValTest_dict['df_test_X'][i] = np.array(TrainValTest_dict['df_test_X'][i])\n",
    "    TrainValTest_dict['df_train_y'][i] = TrainValTest_dict['df_train_y'][i].values\n",
    "    TrainValTest_dict['df_val_y'][i] = TrainValTest_dict['df_val_y'][i].values\n",
    "    TrainValTest_dict['df_test_y'][i] = TrainValTest_dict['df_test_y'][i].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DesignedLinearModel:\n",
    "    def __init__(self, reg=None, lam=None):\n",
    "        if reg is None:\n",
    "            assert lam is None\n",
    "        else:\n",
    "            assert reg in (\"l1\", \"l2\")\n",
    "        self.reg = reg\n",
    "        self.lam = lam\n",
    "\n",
    "        self.w = None\n",
    "        self.fitted=False\n",
    "\n",
    "    @classmethod\n",
    "    def _objective_func_wo_reg(cls, X, y, w):\n",
    "        m = X.shape[0]\n",
    "        obj_func = norm(mul_elemwise(inv_pos(y), X*w-y), 1)/m\n",
    "        return obj_func  \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n = X.shape[1]\n",
    "        w = Variable(n, 1)\n",
    "        if self.reg == 'l1':\n",
    "            prob = Problem(Minimize(self._objective_func_wo_reg(X, y, w)+self.lam*norm(w,1)))\n",
    "        elif self.reg == 'l2':\n",
    "            prob = Problem(Minimize(self._objective_func_wo_reg(X, y, w)+self.lam*sum_squares(w)))\n",
    "        elif self.reg is None:\n",
    "            prob = Problem(Minimize(self._objective_func_wo_reg(X, y, w)))\n",
    "        else:\n",
    "            raise KeyError()\n",
    "\n",
    "        prob.solve()\n",
    "#       print (prob.value)\n",
    "#       print (prob.solver_stats)\n",
    "        self.w = np.array(w.value).reshape(-1)\n",
    "        self.fitted=True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert self.fitted==True\n",
    "        result = X @ self.w\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=DesignedLinearModel()\n",
    "model.fit(X=TrainValTest_dict['df_train_X'][0], y=TrainValTest_dict['df_train_y'][0])\n",
    "pred_val = model.predict(X=TrainValTest_dict['df_val_X'][0])\n",
    "pred_test = model.predict(X=TrainValTest_dict['df_test_X'][0])\n",
    "score_val = score_func(pred_val, TrainValTest_dict['df_val_y'][0])\n",
    "score_test = score_func(pred_test, TrainValTest_dict['df_test_y'][0])\n",
    "print(score_val); print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model=DesignedLinearModel(reg='l1', lam=0.00001)\n",
    "model.fit(X=tmp_dict['df_train_X'][2], y=tmp_dict['df_train_y'][2])\n",
    "pred_val = model.predict(X=tmp_dict['df_val_X'][2])\n",
    "pred_test = model.predict(X=tmp_dict['df_test_X'][2])\n",
    "score_val = score_func(pred_val, tmp_dict['df_val_y'][2])\n",
    "score_test = score_func(pred_test, tmp_dict['df_test_y'][2])\n",
    "print(score_val); print(score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def l1_model(lmd, X_train, y_train, X_val, y_val):\n",
    "    model=DesignedLinearModel(reg='l1', lam=lmd)\n",
    "    model.fit(X_train, y_train)\n",
    "    pred_val = model.predict(X_val)\n",
    "    score_val = score_func(pred_val, y_val)\n",
    "    return score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_test(store_id):\n",
    "    \"\"\"\n",
    "    expecting store id (in string)\n",
    "    and return two data sets of that preticular store\n",
    "    \"\"\"\n",
    "    df_tmp = df_with_onehot[df_with_onehot['air_store_id'] == store_id]\n",
    "    X_test = df_tmp.drop(['air_store_id','visit_date','visitors'],1)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    X_test = X_test.as_matrix()\n",
    "\n",
    "    y_test = df_tmp['visitors']\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    y_test = y_test.as_matrix()\n",
    "    return X_test, y_test\n",
    "\n",
    "def predict_result(model_use, X_test, y_test):\n",
    "    \"\"\"\n",
    "    assuming a model is already trained\n",
    "    \"\"\"\n",
    "    pred_y = model_use.predict(X_test)\n",
    "    score_test = score_func(pred_y, y_test)\n",
    "    return score_test\n",
    "\n",
    "score_store = []\n",
    "for id in store_id_list:\n",
    "    [x_tmp, y_tmp] = create_test(id)\n",
    "    score = predict_result(model, x_tmp, y_tmp) \n",
    "    score_store.append(score)\n",
    "    print(\"running for store %s, test score = %.6f\" %(id, score))\n",
    "print('finished') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
